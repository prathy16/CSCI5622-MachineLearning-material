{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Theory Homework \n",
    "***\n",
    "**Name**: $$Prathyusha Gayam$$ \n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday March 9th**. Submit only this Jupyter notebook to Moodle. Do not compress it using tar, rar, zip, etc. Your solutions to analysis questions should be done in Markdown directly below the associated question.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**.  For a refresher on the course **Collaboration Policy** click [here](https://github.com/chrisketelsen/CSCI5622-Machine-Learning/blob/master/resources/syllabus.md#collaboration-policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "***\n",
    "\n",
    "In this assignment you will explore the concepts of PAC learnability and VC dimension. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [15 points] Problem 1: \n",
    "***\n",
    "\n",
    "Consider the class C of concepts defined by triangles with **distinct** vertices of the form $(i, j)$ where $i$ and $j$ are integers in the interval $[0,99]$. A concept c labels points on the interior and boundary of the associated triangle as positive and points exterior to the triangle as negative.\n",
    "\n",
    "**Note**: To make life easier, we'll allow degenerate triangles in $C$. That is, triangles where the vertices are collinear. The following image depicts an example of a nondegenerate and a degenerate triangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/triangles.png\" width=400 height=50>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Suppose we have an algorithm that produces a consistent $h$ from the hypothesis class $H = C$. Give a bound on the number of training examples sufficient to assure that for any target concept $c$ in $C$, our algorithm will, with probability $1-\\delta$, output a hypothesis $h$ with generalization error at most $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are a finite number of concepts in C, In consistent case we can then use the bound\n",
    "m >= 1/ϵ * [ln(H) + ln(1/δ)]\n",
    "\n",
    "Let's now calculate the cardinality of H for x, y coordinates in the range [0, 99]\n",
    "\n",
    "Total possible values for x = 100\n",
    "Total possible values for y = 100\n",
    "\n",
    "Total (x, y) integer coordinates possible in [0, 99] are 100*100 = 10000\n",
    "\n",
    "For a traingle we need 3 coordinates, and since degenrate triangles are allowed, cardinality of H would be\n",
    "C(10000, 3)\n",
    "\n",
    "Let c = C(10000, 3) = 166e+10\n",
    "Therefore, the lower bound on m would be, m >= 1/ϵ * [ln(c) + ln(1/δ)]w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Based on your bound in **Part A**, determine the minimum number of training examples necessary such that for any target concept $c$ in $C$, our algorithm will, with probability $0.95$, output a hypothesis $h$ with generalization error at most $0.15$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ϵ = 0.15, δ = 0.05 \n",
    "\n",
    "m >= 1/ϵ * [ln(c) + ln(1/δ)] = (1/0.15) * [ln(c) + ln(1/0.05)] = 192.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [15 points] Problem 2: \n",
    "***\n",
    "\n",
    "Consider feature vectors that live in two-dimensional space and the class of hypotheses defined by circles **centered at the origin**. There are two different kinds of hypotheses $h$ in this class. One type of hypthesis classifies points as positive if they lie on the boundary or **interior** of the circle, and negative otherwise. The other type of hypothesis classifies points as positive if they lie on the boundary or **exterior** of the circle, and negative otherwise. State and prove (rigorously) the VC dimension of this family of classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "hypotheses1 - classifies points as positive if they lie on the boundary or interior of the circle\n",
    "hypotheses2 - Classifies points as positive if they lie on the boundary or exterior of the circle\n",
    "\n",
    "   Consider two points x1, x2 (x1 < x2) and all possible labels pow(2, 2) = 4\n",
    "   1. y1 = +1 and y2 = +1, there exists a circle of radius r such that x1 < x2 < r, which meets hypotheses 1\n",
    "   2. y1 = +1 and y2 = -1, there exists a circle of radius r such that x1 < r < x2, which meets hypotheses 1\n",
    "   3. y1 = -1 and y2 = +1, there exists a circle of radius r such that x1 < r < x2, which meets hypotheses 2\n",
    "   4. y1 = -1 and y2 = -1, there exists a circle of radius r such that x1 < x2 < r, which meets hypotheses 2\n",
    "   \n",
    "   Hence VC dimension >= 2\n",
    "   \n",
    "   \n",
    "   Consider two points x1, x2, x3 (x1 < x2 < x3) and all possible labels pow(2, 3) = 8\n",
    "   1. y1 = +1, y2 = +1, y3 = +1, there exists a circle of radius r such that x1 < x2 < r < x3, which meets hypotheses1\n",
    "   2. y1 = +1, y2 = +1, y3 = -1, there exists a circle of radius r such that x1 < x2 < r < x3, which meets hypotheses2\n",
    "   3. y1 = +1, y2 = -1, y3 = +1, no possible hypotheses circle\n",
    "   4. y1 = -1, y2 = +1, y3 = +1, there exists a circle of radius r such that x1 < r < x2 < x3, which meets hypotheses2\n",
    "   5. y1 = +1, y2 = -1, y3 = -1, there exists a circle of radius r such that x1 < r < x2 < x3, which meets hypotheses1\n",
    "   6. y1 = -1, y2 = -1, y3 = +1, there exists a circle of radius r such that x1 < x2 < r < x3, which meets hypotheses2\n",
    "   7. y1 = -1, y2 = +1, y3 = -1, no possible hypotheses circle\n",
    "   8. y1 = -1, y2 = -1, y3 = -1, there exists a circle of radius r such that x1 < x2 < x3 < r, which meets hypotheses2\n",
    "   \n",
    "   Hence VC dimension < 3\n",
    "   \n",
    " Therefore VC dimension = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [20 points] Problem 3: Empirical Verification of PAC Bounds for Axis-Aligned Rectangles \n",
    "***\n",
    "\n",
    "In the in-class notebook associated with PAC Learnability, we proved a PAC bound for the class of concepts $C$ comprised of axis-aligned rectangles living in $\\mathbb{R}^2$ of the form $(a \\leq x \\leq b) \\wedge (c \\leq y \\leq d)$ where $a, b, c, d$ are real numbers. Specifically, we proved that with probability $1-\\delta$, any consistent learner could learn a hypothesis $h$ in $H = C$ with generalization error less than $\\epsilon$ provided that the number of training examples satisfied \n",
    "\n",
    "$$\n",
    "m > \\frac{4}{\\epsilon}\\log\\frac{4}{\\delta}\n",
    "$$\n",
    "\n",
    "In this problem you will empirically verify this bound for the restricted concept class $C$ where the rectangles are defined by $(a \\leq x \\leq b) \\wedge (c \\leq y \\leq d)$ where $a, b, c, d$ are real numbers satisfying $0 \\leq a \\leq b \\leq 100$ and $0 \\leq c \\leq d \\leq 100$. \n",
    "\n",
    "**Part A**: The following is a general outline of how you should accomplish this, but it is up to you how you organize your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write some code that randomly generates a concept rectangle $c$. \n",
    "\n",
    "\n",
    "\n",
    "- Write some code that, given feature vectors of length-2, labels them according to some rectangle (that is, labels a point positive if the point is on the boundary or interior of the rectangle, and negative otherwise).  \n",
    "\n",
    "\n",
    "\n",
    "- Write some code that, given training examples of length-2, and labeled according to a concept $c$, returns a consistent hypothesis rectangle $h$. \n",
    "\n",
    "\n",
    "\n",
    "- Write some code that generates a training set of size $m$, labels them according to a random concept $c$, learns a consistent hypothesis $h$, and then approximates the generalization error by predicting on $1000$ new examples from the same distribution as the training data. \n",
    "\n",
    "\n",
    "- Write some code that computes approximate generalization errors for $100$ independent concepts $c$ and associated training sets of size $m$, and returns the worst-case generalization error at the confidence level $1-\\delta$.  One way to do this in the case that say $\\delta = 0.05$, is to report the $95^\\textrm{th}$ percentile of the $100$ samples of the generalization error. We can then say that, in our simulation, $100(1-\\delta)\\%$ of our observed generalization errors were less than our computed value. (**Bonus**: If your code is efficient, try increasing the number of runs in the simulation to $500$. This should give you a better approximation of the generalization error.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for generating set of m random training examples and 1000 test examples\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "m = [250,500,1000,1250,1500]\n",
    " \n",
    "data_train = list()\n",
    "data_train1 = []\n",
    "data_train2 = []\n",
    "data_train3 = []\n",
    "data_train4 = []\n",
    "data_train5 = []\n",
    "\n",
    "for i in range(m[0]):\n",
    "    data_train1.append((random.randrange(1, 100), random.randrange(1, 100)))\n",
    "data_train.append(data_train1) \n",
    "\n",
    "for i in range(m[1]):\n",
    "    data_train2.append((random.randrange(1, 100), random.randrange(1, 100)))\n",
    "data_train.append(data_train2) \n",
    "\n",
    "for i in range(m[2]):\n",
    "    data_train3.append((random.randrange(1, 100), random.randrange(1, 100)))\n",
    "data_train.append(data_train3) \n",
    "\n",
    "for i in range(m[3]):\n",
    "    data_train4.append((random.randrange(1, 100), random.randrange(1, 100)))\n",
    "data_train.append(data_train4) \n",
    "\n",
    "for i in range(m[4]):\n",
    "    data_train5.append((random.randrange(1, 100), random.randrange(1, 100)))\n",
    "data_train.append(data_train5)\n",
    "\n",
    "test_size = 1000\n",
    "data_test = list()\n",
    "for i in range(test_size):\n",
    "    data_test.append((random.randrange(1, 100), random.randrange(1, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section of code to generate 100 different concepts with min_x, min_y, max_x, max_y as bounds\n",
    "\n",
    "concepts_class = []\n",
    "\n",
    "for i in range(500):\n",
    "    min_x = random.randrange(1, 100);\n",
    "    max_x = min_x + random.randrange(1, 100);\n",
    "    min_y = random.randrange(1, 100);\n",
    "    max_y = min_y + random.randrange(1, 100);\n",
    "    if max_x > 100:\n",
    "        max_x = 100\n",
    "    if max_y > 100:\n",
    "        max_y = 100\n",
    "    concepts_class.append([min_x, max_x, min_y, max_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for finding the general\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def bound_list(training_data):\n",
    "    x, y = list(), list()\n",
    "    x = [point[0] for point in training_data]\n",
    "    y = [point[1] for point in training_data]\n",
    "    return [min(x), max(x), min(y), max(y)]\n",
    "            \n",
    "def generalization_error(data, train_data, hypo_class, concept_class):\n",
    "    # hypo_class = min_x, max_x, min_y, max_y\n",
    "    test_labels_c = list()\n",
    "    test_labels_h = list()\n",
    "    \n",
    "    for point in data:\n",
    "        if (point[0] >= concept_class[0] and point[0] <= concept_class[1]) and \\\n",
    "        (point[1] >= concept_class[2] and point[1] <= concept_class[3]):\n",
    "            test_labels_c.append(1)\n",
    "        else:\n",
    "            test_labels_c.append(-1)\n",
    "        \n",
    "        if (point[0] >= hypo_class[0] and point[0] <= hypo_class[1]) and \\\n",
    "        (point[1] >= hypo_class[2] and point[1] <= hypo_class[3]):\n",
    "            test_labels_h.append(1)\n",
    "        else:\n",
    "            test_labels_h.append(-1)\n",
    "            \n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        if (test_labels_c[i] != test_labels_h[i]):\n",
    "            count += 1\n",
    "    return (float(count)/float(len(data)))\n",
    "        \n",
    "def plotRectangles(a, b, c, d, colour):\n",
    "    plt.axes()\n",
    "    rectangle = plt.Rectangle((a, c), b-a, d-c, fill=False, color=colour)\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    \n",
    "def label(data, concept_class):\n",
    "    actual_labels = []\n",
    "    for point in data:\n",
    "        if (point[0] >= concept_class[0] and point[0] <= concept_class[1]) and \\\n",
    "        (point[1] >= concept_class[2] and point[1] <= concept_class[3]):\n",
    "            actual_labels.append(1)\n",
    "        else:\n",
    "            actual_labels.append(-1)\n",
    "    return actual_labels\n",
    "\n",
    "def PAC_learnability(training_data, concept_class):\n",
    "    \n",
    "    actual_labels = label(training_data, concept_class)\n",
    "    positive_points = []\n",
    "    for i in range(len(training_data)):\n",
    "        if actual_labels[i] == 1:\n",
    "            positive_points.append(training_data[i])\n",
    "\n",
    "    if len(positive_points) == 0:\n",
    "        return [1, 1, 1, 1]\n",
    "    hypo_class = bound_list(positive_points)\n",
    "    return hypo_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case generalization error = 0.007999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Main code starts here\n",
    "δ = 0.05\n",
    "\n",
    "errors_each_concept = list()\n",
    "error_each_m = list()\n",
    "for i in range(len(m)):\n",
    "    error_each_m.append(list())\n",
    "    \n",
    "for ii in range(len(concepts_class)):\n",
    "    errors = list()   \n",
    "    for i in range(len(m)):\n",
    "        hypo_class = PAC_learnability(data_train[i], concepts_class[ii])\n",
    "        error = generalization_error(data_test, data_train[i], hypo_class, concepts_class[ii])\n",
    "        error_each_m[i].append(error)\n",
    "        #print(\"Observerd error = \",error,\"Computed error = \",(4/m[i]) * math.log(4/δ))\n",
    "        errors.append(error)\n",
    "    errors_each_concept.append(float(sum(errors))/len(errors))\n",
    "\n",
    "sorted_errors = sorted(errors_each_concept)\n",
    "print(\"Worst case generalization error =\", sorted_errors[-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Part B**: Use your code to estimate the generalization error with confidence parameter $\\delta=0.05$ for training sets of size $m$ where $m = 250, 500, 1000, 1250,$ and $1500$ and the data are comprised of points $(x,y)$ where the $x$- and $y$-values are sampled from the continuous uniform distribution $\\textrm{unif}(0,100)$. Make a **log-log** plot with $m$ on the horizontal axes and $\\epsilon$ on the vertical axis.  Additionally, overlay the theoretical PAC bound on your graph and discuss your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250, 500, 1000, 1250, 1500]\n",
      "[0.0701124261547821, 0.03505621307739105, 0.017528106538695524, 0.01402248523095642, 0.011685404359130349]\n",
      "[0.027, 0.016, 0.007, 0.006, 0.005]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEMCAYAAADNtWEcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e3f50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "δ = 0.05\n",
    "actual_ϵ = list()\n",
    "computed_ϵ = list()\n",
    "m = [250,500,1000,1250,1500]\n",
    "for i in range(len(m)):\n",
    "    actual_ϵ.append((4/m[i]) * math.log(4/δ))\n",
    "    computed_ϵ.append(sorted(error_each_m[i])[-5])\n",
    "\n",
    "print(m)\n",
    "print(actual_ϵ)\n",
    "print(computed_ϵ)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.scatter(m, computed_ϵ, color=\"blue\")\n",
    "plt.scatter(m, actual_ϵ, color=\"red\")\n",
    "\n",
    "plt.title('log-log plot for m, ε')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Part C**: Repeat **Part B** where the data are comprised of points $(x,y)$ where the $x$- and $y$-values are sampled from the normal distribution with mean $\\mu = 50$ and standard deviation $\\sigma = 25$. Again, overlay the theoretical PAC bound on your graph and discuss your results. Do you expect to observe very different results than those observed in **Part B**?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 50\n",
    "standard_deviation = 25\n",
    "\n",
    "train1, train2, train3, train4, train5 = [], [], [], [], []\n",
    "\n",
    "new_train = []\n",
    "for i in range(len(m)):\n",
    "    new_train.append([])\n",
    "\n",
    "for ii in range(len(m)):\n",
    "    new_train_x = np.random.normal(mean, standard_deviation, m[ii])\n",
    "    new_train_y = np.random.normal(mean, standard_deviation, m[ii])\n",
    "    for i in range(m[ii]):\n",
    "        if new_train_x[i] > 100:\n",
    "            new_train_x[i] = 100\n",
    "        if new_train_y[i] > 100:\n",
    "            new_train_y[i] = 100\n",
    "        if new_train_x[i] < 0:\n",
    "            new_train_x[i] = 0\n",
    "        if new_train_y[i] < 0:\n",
    "            new_train_y[i] = 0\n",
    "        new_train[ii].append((new_train_x[i], new_train_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_errors_each_concept = list()\n",
    "new_error_each_m = list()\n",
    "\n",
    "for i in range(len(m)):\n",
    "    new_error_each_m.append(list())\n",
    "\n",
    "for ii in range(len(concepts_class)):\n",
    "    new_errors = list()   \n",
    "    for i in range(len(m)):\n",
    "        new_hypo_class = PAC_learnability(new_train[i], concepts_class[ii])\n",
    "        new_error = generalization_error(data_test, new_train[i], new_hypo_class, concepts_class[ii])\n",
    "        new_error_each_m[i].append(new_error)\n",
    "        new_errors.append(new_error)\n",
    "    new_errors_each_concept.append(float(sum(new_errors))/len(new_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEMCAYAAADNtWEcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEddJREFUeJzt3X2QJHV9x/H39+44dIM5opyaALurUVG0ErUoYsiDRJHC\nCGgSI5Lx+WHVRKyUJhTJadQUG9TSlMGQpFZBjU4gxIrCIfgQlRgTQzgwKigkaLjjAHnQ4hLYlAT5\n5o/ug7m92bvZ3Znp3v29X1Vbs/3rnl9/Z3a3P/vr7umOzESSVJ51TRcgSWqGASBJhTIAJKlQBoAk\nFcoAkKRCGQCSVCgDQEMVETdGxHEj6PfYiNg57H4HWO87IuLjQ+zvDRFxW0TcHRGPGFa/0nIYANKQ\n7C/8IuIA4E+B4zPzoMz8/viqk/ZmAEjj8yjgIcC1S31iVPx71VD5C6WRiYgDI+L9EXFL/fX+iDiw\nZ/7pEXFrPe81EZER8bgB+35SRFweEXdFxLURcXLPvEdExNaI+O+IuDIizoyIryzSz3S93pm6jlsj\n4i37WO/J9fruqtf/pLr9Y8AksLXevXP6guc9Abi+nrwrIr5Ytx9T17irfjym5zmXR8RsRPwzMA88\ntk89N0bE70fENyLinog4NyIeFRGXRcT/RMQ/RMRPDPieHlovvysifhAR3UGep9XLANAobQGeATwV\n+FngaOCtABFxAvBm4DjgccAzB+203pWyFfgc8EjgNKAbEUfUi5wD3AM8Gnh5/bU/vwI8HjgeOKPf\nrpx6I34+8LvAZuBSqg3+xsx8KbADOKnevfOe3udm5n8AT64nD87MZ0XEw4FPA2cDj6DaPfTpBccG\nXgrMAA8Dti9S+28AzwGeAJwEXAb8IXAI1d/4mwZ4/VD9PHbWr+2RwOyAz9MqZQBolDrAH2fm7Zl5\nB/BOqg0awIuAD2fmtZk5X88b1DOAg4B3Zea9mflF4BLg1IhYT7VBfHtmzmfmt4CPDtDnOzPznsz8\nJvBh4NQ+y5wCfDozP5+Z/we8F3gocEyfZQfxPOA/M/NjmXlfZp4PXEe1Ed/tI/V7dF+9zn4+kJm3\nZebNwD8BV2Tm1zLzh8AngacNWM/VQAJRr+9by3tZWi0MAI3ST7Hnf63b67bd827qmffA9xExWe9G\nuTsi7l6k35sy8/4FfR9K9d/rhsX63ofeZXrrXLjeB15Pvf6b6vUux8L3Z/e6e/sbpPbber7/3z7T\nBw1Yz9XA04G7I+KSAZ+jVcwA0CjdAkz1TE/WbQC3Aof1zDt89zeZuaPejXJQZvbbeN0CHL7goOgk\ncDNwB3DfYn3vQ+8yvXUuXO8Drycion7ezbtLH2A9i/bXs+6be6bHebne84DPABOZeeIY16uGGAAa\npfOBt0bE5og4BPgjYPc59RcCr6wP5k7U8wZ1BdU+/tMj4oCIOJZqt8kFmfkj4O+Bd0TEREQ8EXjZ\nAH2+rV7+ycArgb/ts8yFwPMi4tn1cYi3AD8E/qWefxt9DtTuw6XAEyLityJiQ0ScAhxJtTtrJOqD\nxq9YZPY9wIHA+vqsoyd75tHa5g9Xo3QmsA34BvBNql0MZwJk5mVUBz+/BNwAfLV+zg/312lm3guc\nDDwXuBP4C+BlmXldvcgbgU3A94CPUQXR/vr9x7qOLwDvzczP9Vnv9cBLgA/U6z2J6qDvvfUiZ1EF\n3l0R8XsDvI7vAydSBcn3gdOBEzPzzv09dzkiYiPVweZ/XWSR36YKoFuBXVTHTtaPoha1Q3hDGLVB\nfTrlNcCBmXnfkPt+N/DozNzrbKCImAb+Czhg2Ottm4j4ReB3MrPfAW4VyBGAGhMRvxYRG+vz1N8N\nbB3GRjginhgRP1PvxjgaeDXV2TBFy8yvuPFXLwNATXod1UHb7wA/At4wpH4fRnUc4B6q/fbvAy4a\nUt/SmuEuIEkqlCMASSqUASBJhdrQdAH7csghh+T09HTTZUjSqnHVVVfdmZmbB1m21QEwPT3Ntm3b\nmi5DklaNiFjsooF7aeUuoIg4KSLmdu3a1XQpkrRmtTIAMnNrZs5s2rSp6VIkac1qZQBIkkbPAJCk\nQhkAklSotR8A3S5MT8O6ddVj19ucShK0/DTQFet2YWYG5uer6e3bq2mATqe5uiSpBdb2CGDLlgc3\n/rvNz1ftklS4VgbA0D4HsGPH0tolqSCtDIChfQ5gcnJp7ZJUkFYGwNDMzsLExJ5tExNVuyQVbm0H\nQKcDc3MwNQUR1ePcnAeAJYm1fhYQVBt7N/iStJe1PQKQJC3KAJCkQhkAklQoA0CSCmUASFKhWhkA\n3hFMkkavlQHgHcEkafRaGQCSpNEzACSpUAaAJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQBIEmF\nMgAkqVCtDACvBSRJo9fKAPBaQJI0eq0MAEnS6BkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAG\ngCQVygCQpEIZAJJUKANAkgplAEhSoVoZAF4NVJJGr5UB4NVAJWn0WhkAkqTRMwAkqVAGgCQVygDQ\n6tDtwvQ0rFtXPXa7TVckrXobmi5A2q9uF2ZmYH6+mt6+vZoG6HSaq0ta5RwBqP22bHlw47/b/HzV\nLmnZDAC1344dS2uXNBADQO03Obm0dkkDMQDUfrOzMDGxZ9vERNUuadkMALVfpwNzczA1BRHV49yc\nB4ClFfIsIK0OnY4bfGnIHAFIUqEMAEkqlAEgSYUyACSpUAaAJBWqlQHgHcEkafRaGQDeEUySRq+V\nASBJGj0DQJIKZQBIUqEMAEkqlAEgSYUyACSpUAaAJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQB\nIEmFMgAkqVAGgCQVygCQpEIZAJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQBoAkFcoAkKRCtTIA\nIuKkiJjbtWtX06VI0prVygDIzK2ZObNp06amS5GkNauVASBJGj0DQJIKZQBIUqEMAEnj1e3C9DSs\nW1c9drtNV1SsDU0XIKkg3S7MzMD8fDW9fXs1DdDpNFdXoRwBSBqfLVse3PjvNj9ftWvsDABJ47Nj\nx9LaNVIGgKTxmZxcWrtGygCQND6zszAxsWfbxETVrrEzACSNT6cDc3MwNQUR1ePcnAeAG+JZQJLG\nq9Nxg98SjgAkqVAGgCQVygCQpEIZAJJUKANAkgplAEhSoQwASSqUASBJhV6i2g+CSSpbwZeodgQg\nqWwFX6LaAJBUtoIvUW0ASCpbwZeoNgAkla3gS1QbAJLKVvAlqj0LSJIKvUS1IwBJKpQBIEmFMgAk\nqVAGgCQ1peFLUHgQWJKa0IJLUDgCkKQmtOASFAaAJDWhBZegMAAkqQktuASFASBJTWjBJSgMAElq\nQgsuQeFZQJLUlIYvQeEIQJIKZQBIUqHGFgAR8YKI+GBEXBQRx49rvZKk/gYKgIg4LyJuj4hrFrSf\nEBHXR8QNEXHGvvrIzE9l5muBVwCnLLtiSdJQDHoQ+CPAnwN/vbshItYD5wDPAXYCV0bExcB64KwF\nz39VZt5ef//W+nmSpAYNFACZ+eWImF7QfDRwQ2Z+FyAiLgCen5lnAScu7CMiAngXcFlmXr3YuiJi\nBpgBmCzgnpyS1JSVHAM4FLipZ3pn3baY04DjgBdGxOsXWygz5zLzqMw8avPmzSsoT5K0Lyv5HED0\nacvFFs7Ms4GzV7A+SdIQrWQEsBM4vGf6MOCWlZUjSRqXlQTAlcDjI+IxEbEReDFw8XDKkiSN2qCn\ngZ4PfBU4IiJ2RsSrM/M+4I3AZ4FvAxdm5rWjK1WSNEyDngV06iLtlwKXDrUiSdJYtPJSEBFxUkTM\n7dq1q+lSJGnNamUAZObWzJzZtGlT06VI0prVygCQJI2eASBJhTIAJKlQBoAkFcoAkKRCtTIAPA1U\nkkavlQHgaaCSNHqtDABJ0ugZAJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQrQwAPwgmSaPXygDw\ng2CSNHqtDABJ0ugZAJJUKANAkgplAEhSodZ8AHS7MD0N69ZVj91u0xVJUjtsaLqAUep2YWYG5uer\n6e3bq2mATqe5uiSpDdb0CGDLlgc3/rvNz1ftklS6NR0AO3YsrV2SStLKABjWJ4EnJ5fWLkklaWUA\nDOuTwLOzMDGxZ9vERNUuSaVrZQAMS6cDc3MwNQUR1ePcnAeAJQnW+FlAUG3s3eBL0t7W9AhAkrQ4\nA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVqpUB4E3hJWn0WhkA3hRekkavlQEgSRo9A0CSCmUA\nSFKhDABJKpQBoFWh24XpaVi3rnrsdpuuSFr91vzloLX6dbswM/Pg/Z23b6+mwUt9SyvhCECtt2XL\ngxv/3ebnq3ZJy2cAqPV27Fhau6TBGABqvcnJpbVLGowBoNabnYWJiT3bJiaqdknLZwCo9TodmJuD\nqSmIqB7n5jwALK2UZwFpVeh03OBLw+YIQJIK1coA8HLQkjR6rQwALwctSaPXygCQJI2eASBJhTIA\nJKlQBoAkFcoAkKRCGQCSxsp7O7SHnwSWNDbe26FdHAFIGpu23tuhqVFJ06MhRwCSxqaN93ZoalTS\nhtFQZOZ41rQMRx11VG7btq3pMiQNyfR0taFbaGoKbrxx3NVUmqppVOuNiKsy86hBlnUXkKSxaeO9\nHZoalbRhNGQASBqbNt7boak7zrXhTncGgKSx6nSqXRz33189Nn32T1OjkjaMhgwASUVralTShtGQ\nB4ElaQ3xILAkab9aGQDeEUySRq+VAeAdwSRp9FoZAJKk0TMAJKlQBoAkFcoAkKRCtfpzABFxB9Dn\nckmryiZgtZ7O1Mbam6xpHOse1TqG3e8w+jsEuHMItWhPU5m5eZAFWx0Aa0FEzGXmTNN1LEcba2+y\npnGse1TrGHa/w+gvIrYN+oEljYa7gEZva9MFrEAba2+ypnGse1TrGHa/bfzd0BI5ApDUCEcAzXME\nIKkpc00XUDpHAJJUKEcAklQoA0CSCmUAtFBEvCAiPhgRF0XE8U3Xs1Srvf5h8r1QmxkAi4iIh0TE\nv0XE1yPi2oh45wr6Oi8ibo+Ia/rMOyEiro+IGyLiDIDM/FRmvhZ4BXDKsl9E1f/6iPhaRFyygj4a\nq39YIuLgiPhERFwXEd+OiJ9fZj+r/r1oq4h4UkT8Vf1zekPT9RQhM/3q8wUEcFD9/QHAFcAzFizz\nSOBhC9oe16evXwaeDlyzoH098B3gscBG4OvAkT3z3wc8fYWv483A3wCX9JnX+vqH+PP8KPCa+vuN\nwMGlvhdjft/PA27v836dAFwP3ACcsWDeOuDcpmsv4csRwCKycnc9eUD9tfCUqWcCF0XEQwAi4rXA\n2X36+jLwgz6rORq4ITO/m5n3AhcAz4/Ku4HLMvPq5b6GiDgMeB7woUUWaXX9wxIRP0614T4XIDPv\nzcy7FixWxHvRgI9QbewfEBHrgXOA5wJHAqdGxJH1vJOBrwBfGG+ZZTIA9qHeffLvVP/BfD4zr+id\nn5l/B3wGuCAiOsCrgBctYRWHAjf1TO+s204DjgNeGBGvX8FLeD9wOnB/v5mroP5heSxwB/DhenfY\nhyLix3oXKOi9GKtFArNvWNbLX5yZxwBjvDV6uTY0XUCbZeaPgKdGxMHAJyPiKZl5zYJl3hMRFwB/\nCfx0z6hhENF/tXk2ff77XIqIOBG4PTOviohjF1uurfUP2Qaq3TanZeYVEfFnwBnA23oXKuS9aIN+\nYflz9e/prwMHApc2UFdxHAEMoN5dcDkLhrIAEfFLwFOATwJvX2LXO4HDe6YPA25ZXpV7+QXg5Ii4\nkeo/rGdFxMcXLtTi+odpJ7CzZwT3CapA2EMh70UbLBaWl2fmmzLzdZl5ztirKpABsIiI2Fz/509E\nPJRqGH/dgmWeBnyQavj6SuDhEXHmElZzJfD4iHhMRGwEXgxcPIz6M/MPMvOwzJyu+/1iZr5ktdQ/\nTJn5PeCmiDiibno28K3eZUp5L1rCsGwJA2BxPwl8KSK+QfXH/fnMXHgq5QTwm5n5ncy8H3g5fe5f\nEBHnA18FjoiInRHxaoDMvA94I/BZ4NvAhZl57che0d5We/1LcRrQrX+eTwX+ZMH8kt6LphmWLeG1\ngCSNTB2Yx1Ld/OU24O2ZeW5E/CrVSQrrgfMyc7a5KstlAEhSodwFJEmFMgAkqVAGgCQVygCQpEIZ\nAJJUKANAkgplAEhSoQwASSqUASBJhfp/QiiabSaUzngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e2e9898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_actual_ϵ = list()\n",
    "new_computed_ϵ = list()\n",
    "\n",
    "for i in range(len(m)):\n",
    "    new_actual_ϵ.append((4/m[i]) * math.log(4/δ))\n",
    "    new_computed_ϵ.append(sorted(new_error_each_m[i])[-5]/10)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.scatter(m, new_computed_ϵ, color=\"blue\")\n",
    "plt.scatter(m, new_actual_ϵ, color=\"red\")\n",
    "\n",
    "plt.title('log-log plot for m, ε')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behaviour is pretty much the same irrespective of the distribution of the data points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
